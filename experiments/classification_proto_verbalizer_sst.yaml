dataset:
  name: sst-2
  path: datasets/TextClassification/SST-2

plm:
  model_name: roberta
  model_path: roberta-large
  optimize:
    freeze_para: False
    lr: 0.00003
    weight_decay: 0.01
    scheduler:
      type: 
      num_warmup_steps: 500

checkpoint:
  save_latest: False
  save_best: False

train:
  batch_size: 2
  num_epochs: 0
  train_verblizer: post
  clean: True

test:
  batch_size: 2

template: manual_template
verbalizer: proto_verbalizer

manual_template:
  choice: 3
  file_path: scripts/TextClassification/imdb/manual_template.txt

proto_verbalizer:
  parent_config: verbalizer
  choice: 0
  file_path: scripts/TextClassification/imdb/manual_verbalizer.txt
  lr: 0.01
  mid_dim: 64
  epochs: 50
  multi_verb: proto

  

environment:
  num_gpus: 1
  cuda_visible_devices:
    - 0
  local_rank: 0
  
learning_setting: few_shot

few_shot:
  parent_config: learning_setting
  few_shot_sampling: sampling_from_train
  
sampling_from_train:
  parent_config: few_shot_sampling
  num_examples_per_label: 16
  also_sample_dev: True
  num_examples_per_label_dev: 1
  seed:
    - 2

reproduce:  # seed for reproduction 
  seed: 123  # a seed for all random part
